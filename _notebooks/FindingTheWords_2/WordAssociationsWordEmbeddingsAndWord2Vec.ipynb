{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finding The Words - Word Associations, Word Embeddings and the Word2Vec model\n",
    "##### David Miller - August 2018 - [Link to Github](https://github.com/millerdw/millerdw.github.io/tree/master/_notebooks/FindingTheWords_2)\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "In a previous post on [simple NLP using R](http://millerdw.github.io/_posts/2018-07-23-RSS and Simple Natural Language Processing.html), we developed an algorithm that used frequency analysis of the vocabulary in different texts to cluster those texts together. We looked at a couple of improvements on this theme, including using w-shingling to compare more complex word combinations rather than just vocabulary.\n",
    "\n",
    "In this post I want to develop a couple of those ideas further, and address a few of the shortcomings of those approaches; namely that they are relatively lightweight, and attempt a rather superficial form of unsupervised learning, rather than diving deeper into the meaning of the texts.\n",
    "\n",
    "Finally, I'm going to take a little bit of a dive into the Word2Vec model ...\n",
    "\n",
    "- Word Associations\n",
    "    + Word Roots and Synonyms\n",
    "- Word Embeddings\n",
    "    + Translating words into 'meaning' vectors\n",
    "- Transfer Learnings\n",
    "    + Using the Word2Vec model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word Associations\n",
    "An immediate downside to comparing complete words and vocabulary within texts is that your algorithm is at the mercy of the author; idioms, favoured words, spelling *conventions* (think 'colour' vs 'color'), spelling *mistakes*... If an algorithm doesn't know to recognise the similarities between such differences (i.e. hasn't been explicitly coded, or taught, to do so), then these all add up to a lot of noise in the signal you are trying to process. This can be a serious problem in texts that are condensed, and have very few words to go by, such as a news article.\n",
    "\n",
    "This is an important point to consider when you're working with an NLP problem. Do I try to solve it by preprocessing the data before it reaches my algorithm? Do I try an algorithm that's more robust to some of these issues, say focussing on strings of characters rather than complete words? I think both are viable options, depending on what your goals are, but for the purposes of this post, I'm going to focus on the former. In short, because I'm more interested in document-level text comparison, I think a character-level algorithm is likely to be overkill, and added to this I'm a big believer in a plug-and-play approach to programming, whereby the different components of an algorithm can be separated (see *pre*-processing), upgraded, replaced, generally-messed-with, forgotten, and even reintroduced at a later date, *without affecting any code elsewhere in the project*. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> I'm a big believer in a plug-and-play approach to programming, whereby the different components of an algorithm can be separated (see *pre*-processing), upgraded, replaced, generally-messed-with, forgotten, and even reintroduced at a later date, *without affecting any code elsewhere in the project*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variety is the Spice of Life\n",
    "A lot of work has been published around the idea of cleaning or normalising individual words before they're input into an algorithm. This is often referred to as [stemming or lemmatization](https://nlp.stanford.edu/IR-book/html/htmledition/stemming-and-lemmatization-1.html) the text, and consists of either simply removing suffices until only the core of a word remains (stemming), or performing a more complex analysis over a large vocabulary in order to group the various forms of a word together (lemmatization).\n",
    "\n",
    "\n",
    "Examples...\n",
    "\n",
    "\n",
    "For the purposes of demonstration, I'm going to use the [Porter Stemmer](http://stp.lingfil.uu.se/~marie/undervisning/textanalys16/porter.pdf) algorithm to cleanup our vocabulary. The Porter Stemmer works by applying a set of rules or heuristics in order, to accurately reduce as many words as possible to a 'correct' word stem. However, the English language is rather varied - given its [variety of historical influences](https://www.merriam-webster.com/help/faq-history), and England's more recent history of global trade, colonialism, and various forms of cultural osmosis (see ['pukka'](https://blog.oxforddictionaries.com/2013/06/14/pukka/), ['tattoo'](https://www.tattoo.com/blog/origin-word-tattoo/), ['chit'](https://www.etymonline.com/word/chit)) - which means that such a set of rules will never be perfect. \n",
    "\n",
    "There are lots of different stemming algorithms, but this one is the most widely known, and has the advantage of being published in its own library; [Snowball](http://snowballstem.org/).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> *\"We don't just borrow from other languages; English pursues them down alleyways, beats them unconscious, and rifles their pockets for loose grammar.\"*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting to work\n",
    "For the purposes of this blog, Python is the programming language of choice. Most of my previous NLP work has been in R, so this will be a first for me. The main reason for my doing this is to make use of the wide variety of tools in the Python community, especially libraries such as [Numpy](http://www.numpy.org/), [Plotly](https://plot.ly/), the [Natural Language Toolkit (NLTK)](https://www.nltk.org/index.html), and later, perhaps, [Keras](https://keras.io/) for deep learning. \n",
    "\n",
    "While the Snowball library is included in NLTK, it is also available in a lighter python wrapper called 'PyStemmer'. As with all of these 3rd party libraries, you'll have to install a copy in addition to your Python installation if you're doing this at home. You'll need to open a `cmd` terminal (in Windows) and run `pip install PyStemmer` to install the library, and then import it into the relevant Python script, as usual.\n",
    "\n",
    "Believe it or not, this will also be one of my first attempts to build a Python notebook from scratch, so let me know if you find something that's bad practice or poorly executed - I've been working with C#, a very similar language, for my whole career, and I've had plenty of experience in reading, contemplating, and occasionally fixing other people's work in Python, but I've never had the joy of starting from a blank piece of screen! \n",
    "\n",
    "Anyway, here goes... In the script below, we're going to import the Snowball/PyStemmer library containing the Porter Stemmer algorithm, and apply it to a set of similar-sounding words. Note also that we have the choose the language that we're interested in. This might seem obvious, but it highlights something worth remembering; the algorithm uses a set of fixed rules based on the cases, tenses and plural forms of various words, and these will obviously change depending on the language or dialect used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stemmer Languages available:\t ['danish', 'dutch', 'english', 'finnish', 'french', 'german', 'hungarian', 'italian', 'norwegian', 'porter', 'portuguese', 'romanian', 'russian', 'spanish', 'swedish', 'turkish']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import Stemmer as ps\n",
    "\n",
    "# list available stemmers\n",
    "print('Stemmer Languages available:\\t',ps.algorithms())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw Word\t Stemmed Word\n",
      "general \t general\n",
      "generalizing \t general\n",
      "generalization \t general\n",
      "generalise \t generalis\n",
      "generalising \t generalis\n",
      "generalisation \t generalis\n"
     ]
    }
   ],
   "source": [
    "# create stemmer class\n",
    "stemmer = ps.Stemmer('english')\n",
    "\n",
    "# stemmer examples\n",
    "rawWords = ['general','generalizing','generalization','generalise','generalising','generalisation']\n",
    "\n",
    "print('Raw Word\\t Stemmed Word')\n",
    "for w in rawWords :\n",
    "    print(w,'\\t',stemmer.stemWord(w))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... so it doesn't always work perfectly, see above where it treats the British and Americanised words as having separate word stems. This is because the stemming algorithm uses human-defined rules rather than, say, learning the relationships for itself. Clearly, there are only so many exceptions that can be accounted for, and the specific rules that would stem the British spellings of `generalise` into the word `general` are either too complicated to include or haven't been added yet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Extra] JSON, NewsAPI and building a news dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from newsapi import NewsApiClient\n",
    "\n",
    "news = NewsApiClient(api_key='2bd0b9a9d4594be6b0ceaa26d1861165')\n",
    "\n",
    "all_news = []\n",
    "for i in range(1,11):\n",
    "    all_news.append(news.get_everything(sources='bbc-news,the-verge,abc-news,ary news,associated press,wired,aftenposten,bbc news,bild,blasting news,bloomberg,business insider,engadget,google news,the verge',\n",
    "                                        from_param='2018-10-01',\n",
    "                                        to='2018-10-14',\n",
    "                                        language='en',\n",
    "                                        page_size=100,\n",
    "                                        page=i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[' endofpar ', 'Share this with endofpar ', 'Email endofpar ', 'Facebook endofpar ', 'Messenger endofpar ', 'Messenger endofpar ', 'Twitter endofpar ', 'Pinterest endofpar ', 'WhatsApp endofpar ', 'LinkedIn endofpar ', 'Copy this link endofpar ', 'These are external links and will open in a new window endofpar ', 'Life on the humanitarian frontline is not as you know it, says former BBC journalist Mark Doyle, who now works in the aid sector and gives his personal view on the job done by aid workers in Zambia. endofpar ', 'The men in the photo above may not conform to the classic image of aid workers in Africa. endofpar ', 'A more traditional shots would show a nurse caring for a sick child - and the nurse would quite likely be a visiting European. endofpar ', 'But the vast majority of people who run aid projects on the continent are in fact Africans. endofpar ', 'And a huge amount of their time is necessarily devoted to confronting the difficulties of delivering assistance in remote places with poor roads or flooded tracks.  endofpar ', 'Team leader Robert Ntitima was nearing the end of a 700km (435 mile) journey from the Zambian capital, Lusaka, to the village of Malumba in the far west of the country.  endofpar ', 'He was taking an eye surgeon to operate on patients facing blindness when his car got stuck in a sand drift. As night began to fall, a fire started by a farmer to clear the bush swept towards the vehicle.  endofpar ', 'You may also be interested in: endofpar ', 'The flames threatened to ignite the fuel tank and blow up the car.  endofpar ', 'Mr Ntitima and driver Clinton Bakala had no choice but to beat back the fire with sticks before using their bare hands to dig out the two-tonne vehicle. endofpar ', 'A chain and another four-wheel drive were then used to finally pull the car free. endofpar ', 'Relieved to be out of the sand, Mr Ntitima nevertheless paused to ring his family before setting off again.  endofpar ', 'It was the birthday of his four-year-old daughter, Sally Mika. He promised they would have her party when he eventually got home.        endofpar ', 'It had been a typical day for the aid workers in western Zambia. endofpar ', 'Earlier, the car carrying the eye surgeon, Bruno Kandei, got bogged down on a flooded stretch of road.  endofpar ', 'Dr Kandei is a specialist in correcting blinding trachoma, the leading cause of preventable blindness in the world. endofpar ', 'He is currently working on behalf of international charity Sightsavers. In addition to his surgical skills, he has to be an expert in getting cars out of floods.  endofpar ', '\"Bruno\" is a nickname. His 1980s boyhood friends borrowed it from their expat British schoolteacher in the western Zambian town of Kalabo. The boy and Bruno the teacher were both keen football players. The name \"Bruno\" stuck with the Zambian.   endofpar ', 'Dr Kandei\\'s real first name is \"Kubona\".  endofpar ', '\"In my language \\'Kubona\\' translates into English as \\'the ability to see,\\'\" Dr Kandei, 53, explained. endofpar ', '\"Maybe my name was the Lord\\'s way of showing me I should help cure blindness.\" endofpar ', 'After a two-day journey, team leader Mr Ntitima and Dr Kandei finally reached the small rural clinic where their patients were waiting. endofpar ', 'The cars carrying the dozen or so patients had also got stuck on rough tracks several times. But now everyone was in the right place for the surgery to take place.  endofpar ', 'Latest figures show that nearly 158 million people worldwide are at risk from blinding trachoma, a disease caused by infection of the eye.  endofpar ', 'Around half of these have been treated with antibiotics, but much work remains to be done.   endofpar ', 'Blinding trachoma is one of the so-called neglected tropical diseases, most of which affect very poor communities. Other examples are guinea worm and sleeping sickness. They attract minimal attention because their impact does not generate an immediate medical emergency as is usually the case, for example, with Ebola disease.  endofpar ', 'In many older people blinding trachoma, if untreated, causes in-growing eyelashes. The lashes scratch the eye, causing great pain and, ultimately, blindness. endofpar ', 'The infection thrives in very poor communities without access to a reliable supply of clean water, or toilets. endofpar ', 'Source: WHO, NHS endofpar ', 'Half the village at risk of blindness endofpar ', 'Combating trachoma in Sudan endofpar ', '\"It\\'s like having small spears scratching your eyes all day long,\" said Sibeso Simate, 72, who was waiting for her operation at the rural clinic in western Zambia. endofpar ', '\"They scratch every time you blink,\" the mother of two said. \"Scratch, scratch, scratch, scratch.\" endofpar ', 'The surgery is a relatively simple operation that takes about 20 minutes. It involves rotating the infected eyelid back to its correct position so the eyelashes are no longer scratching the eye.  endofpar ', 'With just a local anaesthetic being used, Ms Simate was happily chatting with her surgeon throughout the procedure.  endofpar ', 'Dr Kandei carried out half a dozen similar operations in the rural clinic before the fading light forced him to stop. endofpar ', 'Conditions there were very basic - there was no electric light.  endofpar ', 'He and his colleagues travel to rural areas for a fortnight every two months to reach patients who cannot make it to hospitals in the larger towns. endofpar ', 'Mr Ntitima made it back home to Lusaka safely. endofpar ', 'His daughter Sally Mika had her wish for a birthday party come true - complete with cake and candles.  endofpar ', 'She also had an extra treat - a visit to an adventure playground. endofpar ', 'The ex-Soviet president says scrapping a Cold War missile deal will undermine nuclear disarmament. endofpar ', 'Stuck for things to do this week? endofpar ', 'Sign up for our newsletter endofpar ']\n",
      "1000\n",
      "{'source': {'id': 'bbc-news', 'name': 'BBC News'}, 'author': 'https://www.facebook.com/bbcnews', 'title': \"Celebrating Africa's aid workers on the frontline\", 'description': \"From fighting fires to digging cars out of flooded roads - the unglamorous realities of the life of Africa's aid workers.\", 'url': 'https://www.bbc.co.uk/news/world-africa-45797123', 'urlToImage': 'https://ichef.bbci.co.uk/news/1024/branded_news/13D23/production/_103778118_zambia.jpg', 'publishedAt': '2018-10-14T23:55:51Z', 'content': 'Image copyright Marcus Perkins Image caption Aid worker Robert Ntitima (R) and his driver Clinton Bakala pictured after beating back a bush fire Life on the humanitarian frontline is not as you know it, says former BBC journalist Mark Doyle, who now works in … [+5826 chars]'}\n",
      "Share this with endofpar \n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup as bs\n",
    "\n",
    "def scrapeArticleUrl(url):\n",
    "    page = requests.get(url)\n",
    "    soup = bs(page.text, 'html.parser')\n",
    "    return [ p.get_text()+' endofpar ' for p in soup('p') ]\n",
    "\n",
    "rawArticles=[]\n",
    "for news in all_news:\n",
    "    rawArticles=rawArticles+news['articles']\n",
    "\n",
    "# dict comprehension syntax - similar to usage in f#, or the foreach library in R\n",
    "rawArticles = {i : rawArticles[i] for i in range(len(rawArticles))}\n",
    "\n",
    "#\n",
    "rawContents = scrapeArticleUrl(rawArticles[1]['url'])\n",
    "#rawContents = {i : scrapeArticleUrl(rawArticles[i]['url']) for i in range(len(rawArticles))}\n",
    "print(rawContents)\n",
    "print(len(rawArticles))\n",
    "print(rawArticles[1])\n",
    "print(rawContents[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Raw Description:\n",
      "From fighting fires to digging cars out of flooded roads - the unglamorous realities of the life of Africa's aid workers.\n",
      "\n",
      "Preprocessed Description:\n",
      "['from', 'fighting', 'fires', 'to', 'digging', 'cars', 'out', 'of', 'flooded', 'roads', '-', 'the', 'unglamorous', 'realities', 'of', 'the', 'life', 'of', 'africa', 'aid', 'workers', 'endofsen', 'endofpar', 'share', 'this', 'with', 'endofpar', 'email', 'endofpar', 'facebook', 'endofpar', 'messenger', 'endofpar', 'messenger', 'endofpar', 'twitter', 'endofpar', 'pinterest', 'endofpar', 'whatsapp', 'endofpar', 'linkedin', 'endofpar', 'copy', 'this', 'link', 'endofpar', 'these', 'are', 'external', 'links', 'and', 'will', 'open', 'in', 'a', 'new', 'window', 'endofpar', 'life', 'on', 'the', 'humanitarian', 'frontline', 'is', 'not', 'as', 'you', 'know', 'it,', 'says', 'former', 'bbc', 'journalist', 'mark', 'doyle,', 'who', 'now', 'works', 'in', 'the', 'aid', 'sector', 'and', 'gives', 'his', 'personal', 'view', 'on', 'the', 'job', 'done', 'by', 'aid', 'workers', 'in', 'zambia', 'endofsen', 'endofpar', 'the', 'men', 'in', 'the', 'photo', 'above', 'may', 'not', 'conform', 'to', 'the', 'classic', 'image', 'of', 'aid', 'workers', 'in', 'africa', 'endofsen', 'endofpar', 'a', 'more', 'traditional', 'shots', 'would', 'show', 'a', 'nurse', 'caring', 'for', 'a', 'sick', 'child', '-', 'and', 'the', 'nurse', 'would', 'quite', 'likely', 'be', 'a', 'visiting', 'european', 'endofsen', 'endofpar', 'but', 'the', 'vast', 'majority', 'of', 'people', 'who', 'run', 'aid', 'projects', 'on', 'the', 'continent', 'are', 'in', 'fact', 'africans', 'endofsen', 'endofpar', 'and', 'a', 'huge', 'amount', 'of', 'their', 'time', 'is', 'necessarily', 'devoted', 'to', 'confronting', 'the', 'difficulties', 'of', 'delivering', 'assistance', 'in', 'remote', 'places', 'with', 'poor', 'roads', 'or', 'flooded', 'tracks', 'endofsen', 'endofpar', 'team', 'leader', 'robert', 'ntitima', 'was', 'nearing', 'the', 'end', 'of', 'a', '700km', '(435', 'mile)', 'journey', 'from', 'the', 'zambian', 'capital,', 'lusaka,', 'to', 'the', 'village', 'of', 'malumba', 'in', 'the', 'far', 'west', 'of', 'the', 'country', 'endofsen', 'endofpar', 'he', 'was', 'taking', 'an', 'eye', 'surgeon', 'to', 'operate', 'on', 'patients', 'facing', 'blindness', 'when', 'his', 'car', 'got', 'stuck', 'in', 'a', 'sand', 'drift', 'endofsen', 'as', 'night', 'began', 'to', 'fall,', 'a', 'fire', 'started', 'by', 'a', 'farmer', 'to', 'clear', 'the', 'bush', 'swept', 'towards', 'the', 'vehicle', 'endofsen', 'endofpar', 'you', 'may', 'also', 'be', 'interested', 'in:', 'endofpar', 'the', 'flames', 'threatened', 'to', 'ignite', 'the', 'fuel', 'tank', 'and', 'blow', 'up', 'the', 'car', 'endofsen', 'endofpar', 'mr', 'ntitima', 'and', 'driver', 'clinton', 'bakala', 'had', 'no', 'choice', 'but', 'to', 'beat', 'back', 'the', 'fire', 'with', 'sticks', 'before', 'using', 'their', 'bare', 'hands', 'to', 'dig', 'out', 'the', 'two-tonne', 'vehicle', 'endofsen', 'endofpar', 'a', 'chain', 'and', 'another', 'four-wheel', 'drive', 'were', 'then', 'used', 'to', 'finally', 'pull', 'the', 'car', 'free', 'endofsen', 'endofpar', 'relieved', 'to', 'be', 'out', 'of', 'the', 'sand,', 'mr', 'ntitima', 'nevertheless', 'paused', 'to', 'ring', 'his', 'family', 'before', 'setting', 'off', 'again', 'endofsen', 'endofpar', 'it', 'was', 'the', 'birthday', 'of', 'his', 'four-year-old', 'daughter,', 'sally', 'mika', 'endofsen', 'he', 'promised', 'they', 'would', 'have', 'her', 'party', 'when', 'he', 'eventually', 'got', 'home', 'endofsen', 'endofpar', 'it', 'had', 'been', 'a', 'typical', 'day', 'for', 'the', 'aid', 'workers', 'in', 'western', 'zambia', 'endofsen', 'endofpar', 'earlier,', 'the', 'car', 'carrying', 'the', 'eye', 'surgeon,', 'bruno', 'kandei,', 'got', 'bogged', 'down', 'on', 'a', 'flooded', 'stretch', 'of', 'road', 'endofsen', 'endofpar', 'dr', 'kandei', 'is', 'a', 'specialist', 'in', 'correcting', 'blinding', 'trachoma,', 'the', 'leading', 'cause', 'of', 'preventable', 'blindness', 'in', 'the', 'world', 'endofsen', 'endofpar', 'he', 'is', 'currently', 'working', 'on', 'behalf', 'of', 'international', 'charity', 'sightsavers', 'endofsen', 'in', 'addition', 'to', 'his', 'surgical', 'skills,', 'he', 'has', 'to', 'be', 'an', 'expert', 'in', 'getting', 'cars', 'out', 'of', 'floods', 'endofsen', 'endofpar', '\"bruno\"', 'is', 'a', 'nickname', 'endofsen', 'his', '1980s', 'boyhood', 'friends', 'borrowed', 'it', 'from', 'their', 'expat', 'british', 'schoolteacher', 'in', 'the', 'western', 'zambian', 'town', 'of', 'kalabo', 'endofsen', 'the', 'boy', 'and', 'bruno', 'the', 'teacher', 'were', 'both', 'keen', 'football', 'players', 'endofsen', 'the', 'name', '\"bruno\"', 'stuck', 'with', 'the', 'zambian', 'endofsen', 'endofpar', 'dr', 'kandei', 'real', 'first', 'name', 'is', '\"kubona\"', 'endofsen', 'endofpar', '\"in', 'my', 'language', \"'kubona'\", 'translates', 'into', 'english', 'as', \"'the\", 'ability', 'to', 'see,\\'\"', 'dr', 'kandei,', '53,', 'explained', 'endofsen', 'endofpar', '\"maybe', 'my', 'name', 'was', 'the', 'lord', 'way', 'of', 'showing', 'me', 'i', 'should', 'help', 'cure', 'blindness.\"', 'endofpar', 'after', 'a', 'two-day', 'journey,', 'team', 'leader', 'mr', 'ntitima', 'and', 'dr', 'kandei', 'finally', 'reached', 'the', 'small', 'rural', 'clinic', 'where', 'their', 'patients', 'were', 'waiting', 'endofsen', 'endofpar', 'the', 'cars', 'carrying', 'the', 'dozen', 'or', 'so', 'patients', 'had', 'also', 'got', 'stuck', 'on', 'rough', 'tracks', 'several', 'times', 'endofsen', 'but', 'now', 'everyone', 'was', 'in', 'the', 'right', 'place', 'for', 'the', 'surgery', 'to', 'take', 'place', 'endofsen', 'endofpar', 'latest', 'figures', 'show', 'that', 'nearly', '158', 'million', 'people', 'worldwide', 'are', 'at', 'risk', 'from', 'blinding', 'trachoma,', 'a', 'disease', 'caused', 'by', 'infection', 'of', 'the', 'eye', 'endofsen', 'endofpar', 'around', 'half', 'of', 'these', 'have', 'been', 'treated', 'with', 'antibiotics,', 'but', 'much', 'work', 'remains', 'to', 'be', 'done', 'endofsen', 'endofpar', 'blinding', 'trachoma', 'is', 'one', 'of', 'the', 'so-called', 'neglected', 'tropical', 'diseases,', 'most', 'of', 'which', 'affect', 'very', 'poor', 'communities', 'endofsen', 'other', 'examples', 'are', 'guinea', 'worm', 'and', 'sleeping', 'sickness', 'endofsen', 'they', 'attract', 'minimal', 'attention', 'because', 'their', 'impact', 'does', 'not', 'generate', 'an', 'immediate', 'medical', 'emergency', 'as', 'is', 'usually', 'the', 'case,', 'for', 'example,', 'with', 'ebola', 'disease', 'endofsen', 'endofpar', 'in', 'many', 'older', 'people', 'blinding', 'trachoma,', 'if', 'untreated,', 'causes', 'in-growing', 'eyelashes', 'endofsen', 'the', 'lashes', 'scratch', 'the', 'eye,', 'causing', 'great', 'pain', 'and,', 'ultimately,', 'blindness', 'endofsen', 'endofpar', 'the', 'infection', 'thrives', 'in', 'very', 'poor', 'communities', 'without', 'access', 'to', 'a', 'reliable', 'supply', 'of', 'clean', 'water,', 'or', 'toilets', 'endofsen', 'endofpar', 'source:', 'who,', 'nhs', 'endofpar', 'half', 'the', 'village', 'at', 'risk', 'of', 'blindness', 'endofpar', 'combating', 'trachoma', 'in', 'sudan', 'endofpar', '\"it', 'like', 'having', 'small', 'spears', 'scratching', 'your', 'eyes', 'all', 'day', 'long,\"', 'said', 'sibeso', 'simate,', '72,', 'who', 'was', 'waiting', 'for', 'her', 'operation', 'at', 'the', 'rural', 'clinic', 'in', 'western', 'zambia', 'endofsen', 'endofpar', '\"they', 'scratch', 'every', 'time', 'you', 'blink,\"', 'the', 'mother', 'of', 'two', 'said', 'endofsen', '\"scratch,', 'scratch,', 'scratch,', 'scratch.\"', 'endofpar', 'the', 'surgery', 'is', 'a', 'relatively', 'simple', 'operation', 'that', 'takes', 'about', '20', 'minutes', 'endofsen', 'it', 'involves', 'rotating', 'the', 'infected', 'eyelid', 'back', 'to', 'its', 'correct', 'position', 'so', 'the', 'eyelashes', 'are', 'no', 'longer', 'scratching', 'the', 'eye', 'endofsen', 'endofpar', 'with', 'just', 'a', 'local', 'anaesthetic', 'being', 'used,', 'ms', 'simate', 'was', 'happily', 'chatting', 'with', 'her', 'surgeon', 'throughout', 'the', 'procedure', 'endofsen', 'endofpar', 'dr', 'kandei', 'carried', 'out', 'half', 'a', 'dozen', 'similar', 'operations', 'in', 'the', 'rural', 'clinic', 'before', 'the', 'fading', 'light', 'forced', 'him', 'to', 'stop', 'endofsen', 'endofpar', 'conditions', 'there', 'were', 'very', 'basic', '-', 'there', 'was', 'no', 'electric', 'light', 'endofsen', 'endofpar', 'he', 'and', 'his', 'colleagues', 'travel', 'to', 'rural', 'areas', 'for', 'a', 'fortnight', 'every', 'two', 'months', 'to', 'reach', 'patients', 'who', 'cannot', 'make', 'it', 'to', 'hospitals', 'in', 'the', 'larger', 'towns', 'endofsen', 'endofpar', 'mr', 'ntitima', 'made', 'it', 'back', 'home', 'to', 'lusaka', 'safely', 'endofsen', 'endofpar', 'his', 'daughter', 'sally', 'mika', 'had', 'her', 'wish', 'for', 'a', 'birthday', 'party', 'come', 'true', '-', 'complete', 'with', 'cake', 'and', 'candles', 'endofsen', 'endofpar', 'she', 'also', 'had', 'an', 'extra', 'treat', '-', 'a', 'visit', 'to', 'an', 'adventure', 'playground', 'endofsen', 'endofpar', 'the', 'ex-soviet', 'president', 'says', 'scrapping', 'a', 'cold', 'war', 'missile', 'deal', 'will', 'undermine', 'nuclear', 'disarmament', 'endofsen', 'endofpar', 'stuck', 'for', 'things', 'to', 'do', 'this', 'week?', 'endofpar', 'sign', 'up', 'for', 'our', 'newsletter', 'endofpar']\n",
      "\n",
      "Stemmed Description:\n",
      "['from', 'fight', 'fire', 'to', 'dig', 'car', 'out', 'of', 'flood', 'road', '-', 'the', 'unglamor', 'realiti', 'of', 'the', 'life', 'of', 'africa', 'aid', 'worker', 'endofsen', 'endofpar', 'share', 'this', 'with', 'endofpar', 'email', 'endofpar', 'facebook', 'endofpar', 'messeng', 'endofpar', 'messeng', 'endofpar', 'twitter', 'endofpar', 'pinterest', 'endofpar', 'whatsapp', 'endofpar', 'linkedin', 'endofpar', 'copi', 'this', 'link', 'endofpar', 'these', 'are', 'extern', 'link', 'and', 'will', 'open', 'in', 'a', 'new', 'window', 'endofpar', 'life', 'on', 'the', 'humanitarian', 'frontlin', 'is', 'not', 'as', 'you', 'know', 'it,', 'say', 'former', 'bbc', 'journalist', 'mark', 'doyle,', 'who', 'now', 'work', 'in', 'the', 'aid', 'sector', 'and', 'give', 'his', 'person', 'view', 'on', 'the', 'job', 'done', 'by', 'aid', 'worker', 'in', 'zambia', 'endofsen', 'endofpar', 'the', 'men', 'in', 'the', 'photo', 'abov', 'may', 'not', 'conform', 'to', 'the', 'classic', 'imag', 'of', 'aid', 'worker', 'in', 'africa', 'endofsen', 'endofpar', 'a', 'more', 'tradit', 'shot', 'would', 'show', 'a', 'nurs', 'care', 'for', 'a', 'sick', 'child', '-', 'and', 'the', 'nurs', 'would', 'quit', 'like', 'be', 'a', 'visit', 'european', 'endofsen', 'endofpar', 'but', 'the', 'vast', 'major', 'of', 'peopl', 'who', 'run', 'aid', 'project', 'on', 'the', 'contin', 'are', 'in', 'fact', 'african', 'endofsen', 'endofpar', 'and', 'a', 'huge', 'amount', 'of', 'their', 'time', 'is', 'necessarili', 'devot', 'to', 'confront', 'the', 'difficulti', 'of', 'deliv', 'assist', 'in', 'remot', 'place', 'with', 'poor', 'road', 'or', 'flood', 'track', 'endofsen', 'endofpar', 'team', 'leader', 'robert', 'ntitima', 'was', 'near', 'the', 'end', 'of', 'a', '700km', '(435', 'mile)', 'journey', 'from', 'the', 'zambian', 'capital,', 'lusaka,', 'to', 'the', 'villag', 'of', 'malumba', 'in', 'the', 'far', 'west', 'of', 'the', 'countri', 'endofsen', 'endofpar', 'he', 'was', 'take', 'an', 'eye', 'surgeon', 'to', 'oper', 'on', 'patient', 'face', 'blind', 'when', 'his', 'car', 'got', 'stuck', 'in', 'a', 'sand', 'drift', 'endofsen', 'as', 'night', 'began', 'to', 'fall,', 'a', 'fire', 'start', 'by', 'a', 'farmer', 'to', 'clear', 'the', 'bush', 'swept', 'toward', 'the', 'vehicl', 'endofsen', 'endofpar', 'you', 'may', 'also', 'be', 'interest', 'in:', 'endofpar', 'the', 'flame', 'threaten', 'to', 'ignit', 'the', 'fuel', 'tank', 'and', 'blow', 'up', 'the', 'car', 'endofsen', 'endofpar', 'mr', 'ntitima', 'and', 'driver', 'clinton', 'bakala', 'had', 'no', 'choic', 'but', 'to', 'beat', 'back', 'the', 'fire', 'with', 'stick', 'befor', 'use', 'their', 'bare', 'hand', 'to', 'dig', 'out', 'the', 'two-tonn', 'vehicl', 'endofsen', 'endofpar', 'a', 'chain', 'and', 'anoth', 'four-wheel', 'drive', 'were', 'then', 'use', 'to', 'final', 'pull', 'the', 'car', 'free', 'endofsen', 'endofpar', 'reliev', 'to', 'be', 'out', 'of', 'the', 'sand,', 'mr', 'ntitima', 'nevertheless', 'paus', 'to', 'ring', 'his', 'famili', 'befor', 'set', 'off', 'again', 'endofsen', 'endofpar', 'it', 'was', 'the', 'birthday', 'of', 'his', 'four-year-old', 'daughter,', 'salli', 'mika', 'endofsen', 'he', 'promis', 'they', 'would', 'have', 'her', 'parti', 'when', 'he', 'eventu', 'got', 'home', 'endofsen', 'endofpar', 'it', 'had', 'been', 'a', 'typic', 'day', 'for', 'the', 'aid', 'worker', 'in', 'western', 'zambia', 'endofsen', 'endofpar', 'earlier,', 'the', 'car', 'carri', 'the', 'eye', 'surgeon,', 'bruno', 'kandei,', 'got', 'bog', 'down', 'on', 'a', 'flood', 'stretch', 'of', 'road', 'endofsen', 'endofpar', 'dr', 'kandei', 'is', 'a', 'specialist', 'in', 'correct', 'blind', 'trachoma,', 'the', 'lead', 'caus', 'of', 'prevent', 'blind', 'in', 'the', 'world', 'endofsen', 'endofpar', 'he', 'is', 'current', 'work', 'on', 'behalf', 'of', 'intern', 'chariti', 'sightsav', 'endofsen', 'in', 'addit', 'to', 'his', 'surgic', 'skills,', 'he', 'has', 'to', 'be', 'an', 'expert', 'in', 'get', 'car', 'out', 'of', 'flood', 'endofsen', 'endofpar', '\"bruno\"', 'is', 'a', 'nicknam', 'endofsen', 'his', '1980s', 'boyhood', 'friend', 'borrow', 'it', 'from', 'their', 'expat', 'british', 'schoolteach', 'in', 'the', 'western', 'zambian', 'town', 'of', 'kalabo', 'endofsen', 'the', 'boy', 'and', 'bruno', 'the', 'teacher', 'were', 'both', 'keen', 'footbal', 'player', 'endofsen', 'the', 'name', '\"bruno\"', 'stuck', 'with', 'the', 'zambian', 'endofsen', 'endofpar', 'dr', 'kandei', 'real', 'first', 'name', 'is', '\"kubona\"', 'endofsen', 'endofpar', '\"in', 'my', 'languag', 'kubona', 'translat', 'into', 'english', 'as', 'the', 'abil', 'to', 'see,\\'\"', 'dr', 'kandei,', '53,', 'explain', 'endofsen', 'endofpar', '\"mayb', 'my', 'name', 'was', 'the', 'lord', 'way', 'of', 'show', 'me', 'i', 'should', 'help', 'cure', 'blindness.\"', 'endofpar', 'after', 'a', 'two-day', 'journey,', 'team', 'leader', 'mr', 'ntitima', 'and', 'dr', 'kandei', 'final', 'reach', 'the', 'small', 'rural', 'clinic', 'where', 'their', 'patient', 'were', 'wait', 'endofsen', 'endofpar', 'the', 'car', 'carri', 'the', 'dozen', 'or', 'so', 'patient', 'had', 'also', 'got', 'stuck', 'on', 'rough', 'track', 'sever', 'time', 'endofsen', 'but', 'now', 'everyon', 'was', 'in', 'the', 'right', 'place', 'for', 'the', 'surgeri', 'to', 'take', 'place', 'endofsen', 'endofpar', 'latest', 'figur', 'show', 'that', 'near', '158', 'million', 'peopl', 'worldwid', 'are', 'at', 'risk', 'from', 'blind', 'trachoma,', 'a', 'diseas', 'caus', 'by', 'infect', 'of', 'the', 'eye', 'endofsen', 'endofpar', 'around', 'half', 'of', 'these', 'have', 'been', 'treat', 'with', 'antibiotics,', 'but', 'much', 'work', 'remain', 'to', 'be', 'done', 'endofsen', 'endofpar', 'blind', 'trachoma', 'is', 'one', 'of', 'the', 'so-cal', 'neglect', 'tropic', 'diseases,', 'most', 'of', 'which', 'affect', 'veri', 'poor', 'communiti', 'endofsen', 'other', 'exampl', 'are', 'guinea', 'worm', 'and', 'sleep', 'sick', 'endofsen', 'they', 'attract', 'minim', 'attent', 'becaus', 'their', 'impact', 'doe', 'not', 'generat', 'an', 'immedi', 'medic', 'emerg', 'as', 'is', 'usual', 'the', 'case,', 'for', 'example,', 'with', 'ebola', 'diseas', 'endofsen', 'endofpar', 'in', 'mani', 'older', 'peopl', 'blind', 'trachoma,', 'if', 'untreated,', 'caus', 'in-grow', 'eyelash', 'endofsen', 'the', 'lash', 'scratch', 'the', 'eye,', 'caus', 'great', 'pain', 'and,', 'ultimately,', 'blind', 'endofsen', 'endofpar', 'the', 'infect', 'thrive', 'in', 'veri', 'poor', 'communiti', 'without', 'access', 'to', 'a', 'reliabl', 'suppli', 'of', 'clean', 'water,', 'or', 'toilet', 'endofsen', 'endofpar', 'source:', 'who,', 'nhs', 'endofpar', 'half', 'the', 'villag', 'at', 'risk', 'of', 'blind', 'endofpar', 'combat', 'trachoma', 'in', 'sudan', 'endofpar', '\"it', 'like', 'have', 'small', 'spear', 'scratch', 'your', 'eye', 'all', 'day', 'long,\"', 'said', 'sibeso', 'simate,', '72,', 'who', 'was', 'wait', 'for', 'her', 'oper', 'at', 'the', 'rural', 'clinic', 'in', 'western', 'zambia', 'endofsen', 'endofpar', '\"they', 'scratch', 'everi', 'time', 'you', 'blink,\"', 'the', 'mother', 'of', 'two', 'said', 'endofsen', '\"scratch,', 'scratch,', 'scratch,', 'scratch.\"', 'endofpar', 'the', 'surgeri', 'is', 'a', 'relat', 'simpl', 'oper', 'that', 'take', 'about', '20', 'minut', 'endofsen', 'it', 'involv', 'rotat', 'the', 'infect', 'eyelid', 'back', 'to', 'it', 'correct', 'posit', 'so', 'the', 'eyelash', 'are', 'no', 'longer', 'scratch', 'the', 'eye', 'endofsen', 'endofpar', 'with', 'just', 'a', 'local', 'anaesthet', 'be', 'used,', 'ms', 'simat', 'was', 'happili', 'chat', 'with', 'her', 'surgeon', 'throughout', 'the', 'procedur', 'endofsen', 'endofpar', 'dr', 'kandei', 'carri', 'out', 'half', 'a', 'dozen', 'similar', 'oper', 'in', 'the', 'rural', 'clinic', 'befor', 'the', 'fade', 'light', 'forc', 'him', 'to', 'stop', 'endofsen', 'endofpar', 'condit', 'there', 'were', 'veri', 'basic', '-', 'there', 'was', 'no', 'electr', 'light', 'endofsen', 'endofpar', 'he', 'and', 'his', 'colleagu', 'travel', 'to', 'rural', 'area', 'for', 'a', 'fortnight', 'everi', 'two', 'month', 'to', 'reach', 'patient', 'who', 'cannot', 'make', 'it', 'to', 'hospit', 'in', 'the', 'larger', 'town', 'endofsen', 'endofpar', 'mr', 'ntitima', 'made', 'it', 'back', 'home', 'to', 'lusaka', 'safe', 'endofsen', 'endofpar', 'his', 'daughter', 'salli', 'mika', 'had', 'her', 'wish', 'for', 'a', 'birthday', 'parti', 'come', 'true', '-', 'complet', 'with', 'cake', 'and', 'candl', 'endofsen', 'endofpar', 'she', 'also', 'had', 'an', 'extra', 'treat', '-', 'a', 'visit', 'to', 'an', 'adventur', 'playground', 'endofsen', 'endofpar', 'the', 'ex-soviet', 'presid', 'say', 'scrap', 'a', 'cold', 'war', 'missil', 'deal', 'will', 'undermin', 'nuclear', 'disarma', 'endofsen', 'endofpar', 'stuck', 'for', 'thing', 'to', 'do', 'this', 'week?', 'endofpar', 'sign', 'up', 'for', 'our', 'newslett', 'endofpar']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def preprocessArticles(articles) :\n",
    "    reEndOfSentence = re.compile('\\\\. ')\n",
    "    reNonAlphaNumeric = re.compile('\\'s|/\\n/|/\\t/|[\\W]+ | ')\n",
    "    processedArticles = {}\n",
    "    for i,article in articles.items() :\n",
    "        # collect contents\n",
    "        contents = [str(article['description'])+' ']+scrapeArticleUrl(article['url'])\n",
    "        # convert contents into words\n",
    "        words = []\n",
    "        for text in contents:\n",
    "            # covert to lower case\n",
    "            text = text.lower()\n",
    "            # replace full stops with ENDOFSEN\n",
    "            text = reEndOfSentence.sub(' endofsen ',text)\n",
    "            # split text into individual words\n",
    "            newWords = text.split(' ')\n",
    "            # remove remaining non-alphanumerics\n",
    "            newWords = [reNonAlphaNumeric.sub('',word) for word in newWords]\n",
    "            words = words + [word for word in newWords if word!='']\n",
    "\n",
    "        # combine into list of processed articles\n",
    "        processedArticles[i] = words\n",
    "        \n",
    "    return processedArticles\n",
    "\n",
    "def stemText(words) :\n",
    "    return [stemmer.stemWord(word) for word in words]\n",
    "\n",
    "def stemArticles(articles) :\n",
    "    return {i:stemText(words) for i,words in articles.items()}\n",
    "\n",
    "\n",
    "articles = preprocessArticles(rawArticles)\n",
    "stemmedArticles = stemArticles(articles)\n",
    "\n",
    "print('\\nRaw Description:')\n",
    "print(rawArticles[1]['description'])\n",
    "print('\\nPreprocessed Description:')\n",
    "print(articles[1])\n",
    "print('\\nStemmed Description:')\n",
    "print(stemmedArticles[1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorised Representations\n",
    "\n",
    "In my previous post, we built an algorithm that looked at the differences between articles in order to cluster them together. In that example, we only needed to generate a difference score between the vocabulary used in two texts, and \n",
    "\n",
    "We didn't have to describe the articles outside of this comparison. This simplified matters for us, but did limit the further tools available to us, \n",
    "\n",
    "very simple, vector defines whole text\n",
    "\n",
    "Because stemming makes similar words match with each other, this should reduce the size of the vocabulary.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Vocabulary:\t(1000, 37270)\n",
      "Stemmed Vocabulary:\t(1000, 30752)\n"
     ]
    }
   ],
   "source": [
    "def buildVocabulary(processedArticles):\n",
    "    # generate list of all vocabulary\n",
    "    vocabulary = []\n",
    "    for i,article in processedArticles.items():\n",
    "        vocabulary = vocabulary + article\n",
    "    \n",
    "    vocabulary = list(set(vocabulary))\n",
    "    vocabulary.sort(key=str)\n",
    "\n",
    "    #return as dictionary\n",
    "    return {i:vocabulary[i] for i in range(len(vocabulary))}\n",
    "\n",
    "def vectoriseText(vocabToIndexMap,article):\n",
    "    # encode words as their index in the vocabulary (e.g. possibly 'aardvark' => 23)\n",
    "    indexArray=[vocabToIndexMap[word] for word in article]\n",
    "    # transform each\n",
    "    frequencyVector=[float(np.sum([i==j for j in indexArray])) for i in range(len(vocabToIndexMap))]\n",
    "    return frequencyVector/np.linalg.norm(frequencyVector)\n",
    "\n",
    "def vectoriseArticles(processedArticles):\n",
    "    # build vocabulary\n",
    "    vocabulary = buildVocabulary(processedArticles)\n",
    "    # create map of word to vocabulary index\n",
    "    vocabToIndexMap={w:i for i,w in vocabulary.items()}\n",
    "    # convert to 2d numpy array of vectors\n",
    "    vectorisedArticles = np.vstack([vectoriseText(vocabToIndexMap,article) for i,article in processedArticles.items()])\n",
    "    return vectorisedArticles, vocabulary\n",
    "    \n",
    "  \n",
    "vectorisedArticles, vocabulary = vectoriseArticles(articles)\n",
    "vectorisedStemmedArticles, stemmedVocabulary = vectoriseArticles(stemmedArticles)\n",
    "\n",
    "print('Original Vocabulary:\\t'+str(vectorisedArticles.shape))\n",
    "print('Stemmed Vocabulary:\\t'+str(vectorisedStemmedArticles.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The numbers above show the size of our matrices. Dimension 1, the number or rows, should equal roughly 1000 in both cases; while dimension 2, the number of columns, will vary depending on the number of the size of the vocabulary used in each case.\n",
    "\n",
    "**As expected, the original vocabulary (untreated) is significantly higher than the stemmed vocabulary.**\n",
    "\n",
    "Now, each of these sets of `vectorisedArticles` is a table, or matrix, with one row for every article, and one column for every word in the vocabulary, the value in each cell, or element, is the number of times the word (column) appears in the article (row).\n",
    "\n",
    "This gives us an n-dimensional map of where ...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculation Time, Original Vectors: 2.5\n",
      "Calculation Time, Stemmed Vectors: 2.0625\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "def singleCalculationTime(vectorisedArticles):\n",
    "    timeStart=time.process_time()\n",
    "    totalDistances=np.dot(vectorisedArticles,vectorisedArticles.T)\n",
    "    timeEnd=time.process_time()\n",
    "    return (timeEnd-timeStart)\n",
    "\n",
    "print('Calculation Time, Original Vectors: '+str(singleCalculationTime(vectorisedArticles)))\n",
    "\n",
    "print('Calculation Time, Stemmed Vectors: '+str(singleCalculationTime(vectorisedStemmedArticles)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def winsoriseWordVectors(vectorisedArticles,vocabulary):\n",
    "    wordFrequency = np.sum(vectorisedArticles,axis=0)\n",
    "    #print(wordFrequency.shape)\n",
    "    #print(np.max(wordFrequency))\n",
    "    #print(np.median(wordFrequency))\n",
    "    wordFrequencyDeciles = np.percentile(wordFrequency,[i for i in range(100)], interpolation='higher')\n",
    "    #print(wordFrequencyDeciles)\n",
    "    columnIndeces=[i for i in range(wordFrequency.shape[0]) if wordFrequency[i]>wordFrequencyDeciles[20] and wordFrequency[i]<=wordFrequencyDeciles[80]]\n",
    "    #print(columnIndeces)\n",
    "    return vectorisedArticles[:,columnIndeces],{i:vocabulary[columnIndeces[i]] for i in range(len(columnIndeces))}\n",
    "\n",
    "winsrVectorArticles,winsrVocabulary = winsoriseWordVectors(vectorisedArticles,vocabulary)\n",
    "winsrVectorStemmedArticles,winsrStemmedVocabulary = winsoriseWordVectors(vectorisedStemmedArticles,stemmedVocabulary)\n",
    "\n",
    "print('Winsorised Original Vocabulary:\\t'+str(winsrVectorArticles.shape))\n",
    "print('Calculation Time, Winsorised Original Vectors: '+str(singleCalculationTime(winsrVectorArticles)))\n",
    "print('Winsorised Stemmed Vocabulary:\\t'+str(winsrVectorStemmedArticles.shape))\n",
    "print('Calculation Time, Winsorised Stemmed Vectors: '+str(singleCalculationTime(winsrVectorStemmedArticles)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorised k-Means\n",
    "\n",
    "\n",
    "cosine similarity, automatically normalises"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosineSimilarity(vectorA,vectorB):\n",
    "    vectorA = [float(element) for element in vectorA]\n",
    "    vectorB = [float(element) for element in vectorB]\n",
    "    return np.dot(vectorA,vectorB)/(np.linalg.norm(vectorA)*np.linalg.norm(vectorB))\n",
    "\n",
    "def centroidDistances(centroids,article):\n",
    "    return { k:cosineSimilarity(centroid,article) for k,centroid in centroids.items() }\n",
    "\n",
    "def generateCentroid(vectorisedArticles):\n",
    "    randId=np.random.randint(vectorisedArticles.shape[0], size=1)\n",
    "    return vectorisedArticles[randId]\n",
    "\n",
    "def kMeansCluster(vectorisedArticles,K,G):\n",
    "\n",
    "    centroids = np.vstack([ generateCentroid(vectorisedArticles) for k in range(K) ])\n",
    "    articleCentroidIds = []\n",
    "    performance=[]\n",
    "    g = 0\n",
    "    centroidsChanged=True\n",
    "    while (g<G and centroidsChanged):\n",
    "        # generate simple cosine distance on normalised vectors between all articles and centroids\n",
    "        centroidDistances=1-np.dot(vectorisedArticles,centroids.T)\n",
    "        #if g==0: print(centroidDistances.shape)\n",
    "        #if g==0: print(centroidDistances)\n",
    "\n",
    "        # use numpy argmin to find index (column) of nearest centroid by article (row)\n",
    "        articleCentroidIds=np.argmin(centroidDistances,axis=1)\n",
    "        articleCentroidDistances=np.min(centroidDistances,axis=1)\n",
    "        #if g==0: print(articleCentroidIds.shape)\n",
    "        #if g==0: print(articleCentroidDistances)\n",
    "        #if g==0: print(articleCentroidIds)\n",
    "        \n",
    "        # create new centroids by averaging positions of all article vectors in cluster\n",
    "        newCentroids=[]\n",
    "        for k in range(K):\n",
    "            clusterMembers=vectorisedArticles[[i for i in range(articleCentroidIds.shape[0]) if articleCentroidIds[i]==k],:]\n",
    "            if g==G-1: print(str(k)+'\\t'+str(clusterMembers.shape))\n",
    "            clusterSize = clusterMembers.shape[0]\n",
    "            if clusterSize==0:\n",
    "                newCentroid=generateCentroid(vectorisedArticles)\n",
    "            else:\n",
    "                newCentroid=np.mean(clusterMembers,axis=0)\n",
    "            newCentroids.append(newCentroid)\n",
    "        newCentroids=np.vstack(newCentroids)\n",
    "\n",
    "        # update existing centroids\n",
    "        #print(centroids-newCentroids)\n",
    "        \n",
    "        centroidsChanged = (np.sum(np.diag(np.dot(centroids,newCentroids.T))<1.0)>0)\n",
    "        centroids=newCentroids\n",
    "        g+=1\n",
    "        \n",
    "        interCentroidDistance = np.sum(np.sum(1-np.dot(newCentroids,newCentroids.T)))/(2*K*(K-1))\n",
    "        intraCentroidDistance = np.mean(articleCentroidDistances)\n",
    "        performance.append([g,interCentroidDistance,intraCentroidDistance,intraCentroidDistance/interCentroidDistance])\n",
    "        \n",
    "    print('Last Generation:\\t'+str(g))\n",
    "    return articleCentroidIds,centroids,np.vstack(performance)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K=50\n",
    "G=10000\n",
    "articleCentroidIds,centroids,performance = kMeansCluster(winsrVectorArticles,K,G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "performance[1:10,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly\n",
    "import plotly.graph_objs as go\n",
    "plotly.offline.init_notebook_mode(connected=True)\n",
    "\n",
    "plotly.offline.iplot({\n",
    "    \"data\": [go.Scatter(x=performance[:,0], y=performance[:,3])],\n",
    "    \"layout\": go.Layout(title=\"hello world\")\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['officially', 'named', '18-year-old', 'taylor', 'smith', 'as', 'a', 'suspect', 'in', 'the', 'frightening', 'video', 'where', 'jordan', 'holgerson', 'is', 'pushed', 'off', 'a']\n",
      "['jordanian', 'immigrant', 'has', 'been', 'sentenced', 'to', 'death', 'in', 'texas', 'for', 'the', 'fatal', 'shootings', 'of', 'his', 'son-in-law', 'and', 'daughter', 'best']\n",
      "['croatia', 'striker', 'mario', 'mandzukic', 'announces', 'his', 'retirement', 'from', 'international', 'football', 'at', 'the', 'age', 'of', '32', 'endofsen', 'endofpar', 'endofpar', 'endofpar']\n",
      "['fla', 'endofsen', '--', 'the', 'miami', 'dolphins', 'could', 'be', 'without', 'devante', 'parker', 'for', 'some', 'time', 'after', 'the', 'receiver', 'suffered', 'a']\n",
      "['world', 'heavyweight', 'champion', 'tyson', 'fury', 'says', 'his', 'old', 'self', 'is', '\"never', 'to', 'be', 'seen', 'again', 'in', 'history\"', 'as', 'he']\n",
      "['exclusion', 'of', 'an', 'autistic', 'boy', 'after', 'he', 'hit', 'a', 'teaching', 'assistant', 'with', 'a', 'ruler,', 'punched', 'her', 'and', 'pulled', 'her']\n",
      "['girls', 'were', 'leaving', 'a', 'gas', 'station', 'convenience', 'store', 'in', 'millington,', 'michigan,', 'last', 'week', 'when', 'a', 'man', 'grabbed', 'one', 'of']\n",
      "['girls', 'were', 'leaving', 'a', 'convenience', 'store', 'when', 'they', 'were', 'attacked', 'endofsen', '\\npolice', 'in', 'michigan', 'say', 'four', 'girls', 'managed', 'to']\n",
      "['man', 'was', 'on', 'holiday', 'when', 'the', 'tree', 'came', 'crashing', 'down', 'at', 'a', 'cornish', 'country', 'park', 'during', 'strong', 'winds', 'endofsen']\n",
      "['rhinos', 'sign', '18-year-old', 'callum', 'mclelland', 'on', 'a', 'three-and-a-half-year', 'deal', 'as', 'he', 'returns', 'to', 'rugby', 'league', 'endofsen', 'endofpar', 'endofpar', 'endofpar']\n",
      "['breaking', 'national', 'and', 'world', 'news,', 'broadcast', 'video', 'coverage,', 'and', 'exclusive', 'interviews', 'endofsen', 'find', 'the', 'top', 'news', 'online', 'at', 'abc']\n",
      "['proposed', 'revamp', 'of', 'the', 'davis', 'cup', 'would', \"'kill'\", 'the', 'competition,', 'says', 'german', 'tennis', 'federation', 'vice-president', 'dirk', 'hordorff', 'endofsen', 'endofpar']\n"
     ]
    }
   ],
   "source": [
    "k=4\n",
    "for i in range(articleCentroidIds.shape[0]):\n",
    "    if articleCentroidIds[i]==k:\n",
    "        print(articles[i][1:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The trouble is, this doesn't work very well...\n",
    "\n",
    "Could be to do with the size of the vectors...\n",
    "\n",
    "plot cluster quality with generations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word Embeddings\n",
    "Superficial text vs deeper meaning\n",
    "\n",
    "Text frequency vectors imply all words are distinct and orthogonal, which is not true. Tunguska is strongly related to the words Incident and Meteor, despite being superficially dissimilar to both\n",
    "\n",
    "This is due to **context** and **understanding** of the words"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
