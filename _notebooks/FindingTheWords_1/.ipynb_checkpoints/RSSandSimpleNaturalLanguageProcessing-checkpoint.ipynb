{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finding The Words - RSS and Simple Natural Language Processing in R\n",
    "##### David Miller - July 2018 - [Link to Github](https://github.com/millerdw/millerdw.github.io/tree/master/_notebooks/FindingTheWords_1)\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Changing tack a little since my last post in [Agricultural Approaches](), I wanted to skip ahead to something I'm particularly interested in. This is a big segue from my previous posts (not segway, that's something else entirely), hence the start of a new blog series. This way, I'm hoping to swap backwards and forwards between simple and higher level concepts, and between different subjects without bamboozling myself, or indeed anyone else, in the process.\n",
    "\n",
    "I'm really interested in the ways in which algorithms can be used to analyse text. There is a profound amount of content, both generated historically and produced daily, that is based in language. Words are the closest humans have to representations of distinct ideas, and it's absolutely incredible how we use them.\n",
    "\n",
    "At the risk of falling into a recursive loop; consider what I've written so far on the page, and how the black and white scratchings have (hopefully) conveyed meaning well above and beyond the pixels that make them up. Consider further how figurative language like \"scratchings\" and \"above and beyond\" don't just provide a literal meaning, but tap into associations that are common between a writer and their audience. Consider even further how when I refer to \"a writer\" and \"their audience\", even without any further information it's clear that I'm referring to myself and all of you because that's how people with an admittedly flowery disposition with words have spoken to you in the past... Consider even further again how... gaahhh abort,abort,abort...\n",
    "\n",
    "Language is incredibly powerful and is a perfect insight into how humans not only perceive, but understand, the world around them. Beyond this, it has been shown that *Language affects a human's understanding of the world*; there is a feedback effect, whereby as language is learnt, our vocabulary *affects* how we differentiate between real world stimuli. This is known as the [Sapir-Whorf Hypothesis](http://www.linguisticsnetwork.com/wp-content/uploads/What-is-the-Sapir_Whorf-Hypothesis.compressed.pdf), and it might just be my favourite of all the 'ideas' or theories that I've ever come across (tied closely with the supposed etymology of the word \"foreign\" but, as this is probably apocryphal, I'll leave it for another time).\n",
    "\n",
    "It's for these reasons I believe that understanding language is the key to understanding how we think. In this blog I want to explore the ways in which an algorithm can begin to get a handle on the former, and the steps required for us to begin to approximate the latter. \n",
    "\n",
    "I'll start with pretty simple ideas, because I'm learning here too, but hopefully we'll progress into areas that are genuinely taxing and interesting. Anyway, I've rambled on enough, I hope you enjoy it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spit it Out\n",
    "\n",
    "I always find that it's best to start with a good example, or project, in mind. In this case, I've been interested in the disparity between reportage of different news outlets for some time, even more so since the tail has begun to wag the dog in terrifying ways (see the EU Referendum and the 2016 US Election). I don't mean that as a political point, it's more that I remember the shock of finding out, twice in a year, that what I'd thought was a sure bet, what everything I'd read had said was a sure thing, turned out to be anything but. I decided that in an ideal world, whatever a persons views were, whatever their voting intention, everyone should be presented with the same facts, without bias or agenda. In reality this is near impossible, but the next best thing, surely, is to take all of those different biased and agenda driven publications, on both sides of the argument, and play them off against each other.\n",
    "\n",
    "The trouble is, this data doesn't come nicely labelled for us. There are often tags telling us roughly what topic an article relates to (e.g. World, Sport, Lifestyle), but not describing the specific story. So, for the course of this series, my aim will be to **group different articles together based solely on their content**. \n",
    "\n",
    "I'm going to try and get stuck in as soon as possible and work things out as I go along, as is my habit, so hold on if the narrative takes a leap of faith or two, but hopefully you'll be able to see a structure emerge as we make some progress.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Straight from the horse's mouth\n",
    "## Accesssing RSS feeds\n",
    "\n",
    "First things first, I'm going to walk through **collecting data from RSS feeds using an R library**. \n",
    "\n",
    "I'm using R in this case because it was the language that I originally began to prototype my model in when I started a few months back, and frankly it seems like a waste of time translating it into something else. I like to think I'm a clean coder though, so regardless of you're own personal preference of the tools to use, you should be able to follow along.\n",
    "\n",
    "[RSS](https://en.wikipedia.org/wiki/RSS) (has lots of bacronymic translations, but I know it as Really Simple Syndication) feeds are just streams of text-based content organised in something akin to an XML format. It contains markers to denote the start and end of objects within the text stream, and has a limited set of properties for each object (Date, Title, Author, and so on). RSS appears to be falling out of favour lately, being replaced mainly by [json](https://www.json.org/) (JavaScript Object Notation), which allows for more flexibility in the objects being passed and parsed between the source server and the consumer application. More on that at another time, I guess.\n",
    "\n",
    "Because of this common structure in RSS, it is *very* easy to parse the text stream into lists of objects in a programming environment, as a result there are lots of libraries available to help you do this, especially in an very open community like R's. Here I'm using a library called [feedeR](https://cran.r-project.org/web/packages/feedeR/index.html) to do the dirty work for me\n",
    "\n",
    "**[Note]** A word of warning, always remember that the library your downloading is written by someone else who may or may not be a better, more diligent, or more motivated developer than you. This may not matter a jot (as in this case), but if you're considering building applications off of one then remember that you'll have absolutely noone to blame but yourself if a nasty bug emerges from said library at a later point in time. Remember also that each library will have a set of it's own weird dependencies, so you can download one or two and in reality be relying on five or ten different sets of code. (Being a .NET developer originally, I try to avoid building full blown apps in R anyway - there are better tools for that so use them - that said, very little beats this language in terms of prototyping and ad hoc analysis).\n",
    "\n",
    "Below I've gone through the process of installing and loading all of the libraries relevant to our cause:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Installing packages into 'C:/Users/David/Documents/R/win-library/3.3'\n",
      "(as 'lib' is unspecified)\n",
      "Warning message:\n",
      "\"packages 'feedeR', 'foreach', 'doParallel' are in use and will not be installed\""
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "package 'stringdist' successfully unpacked and MD5 sums checked\n",
      "package 'rvest' successfully unpacked and MD5 sums checked\n",
      "\n",
      "The downloaded binary packages are in\n",
      "\tC:\\Users\\David\\AppData\\Local\\Temp\\Rtmp0SzSox\\downloaded_packages\n"
     ]
    }
   ],
   "source": [
    "install.packages(c(\"stringdist\",\"feedeR\",\"foreach\",\"doParallel\",\"rvest\",\"magrittr\"))\n",
    "\n",
    "library(doParallel)\n",
    "registerDoParallel(makeCluster(4))\n",
    "\n",
    "library(foreach)\n",
    "library(magrittr)\n",
    "\n",
    "library(feedeR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yes, forgive me, I've set up a library to add a little parallelism-juice to the process. This works simply with the [foreach](https://cran.r-project.org/web/packages/foreach/index.html) library. I've also included [magrittr](https://cran.r-project.org/web/packages/magrittr/index.html) to make R more like FSharp...\n",
    "\n",
    "Now for the more interesting part. Below I've listed a series of active RSS sites I was able to find through google (hopefully of  different political persuasions), and I'm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Space required after the Public Identifier\n",
      "SystemLiteral \" or ' expected\n",
      "SYSTEM or PUBLIC, the URI is missing\n",
      "Space required after the Public Identifier\n",
      "SystemLiteral \" or ' expected\n",
      "SYSTEM or PUBLIC, the URI is missing\n",
      "Space required after the Public Identifier\n",
      "SystemLiteral \" or ' expected\n",
      "SYSTEM or PUBLIC, the URI is missing\n",
      "Space required after the Public Identifier\n",
      "SystemLiteral \" or ' expected\n",
      "SYSTEM or PUBLIC, the URI is missing\n",
      "Space required after the Public Identifier\n",
      "SystemLiteral \" or ' expected\n",
      "SYSTEM or PUBLIC, the URI is missing\n",
      "Space required after the Public Identifier\n",
      "SystemLiteral \" or ' expected\n",
      "SYSTEM or PUBLIC, the URI is missing\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>feed</th><th scope=col>title</th><th scope=col>date</th><th scope=col>link</th><th scope=col>hash</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td>BBC News - World                                                   </td><td>Trump-Putin summit: US president reverses remark on Russia meddling</td><td>2018-07-17 20:52:59                                                </td><td>https://www.bbc.co.uk/news/world-us-canada-44864739                </td><td>0bc39dc7f5641a1d                                                   </td></tr>\n",
       "\t<tr><td>BBC News - World                                                   </td><td>Barack Obama condemns disregard for facts                          </td><td>2018-07-17 18:31:16                                                </td><td>https://www.bbc.co.uk/news/world-africa-44858937                   </td><td>ff2a4b417287dd7e                                                   </td></tr>\n",
       "\t<tr><td>BBC News - World                                                   </td><td>Alabama employee gets new car from boss after 20-mile walk         </td><td>2018-07-17 16:20:18                                                </td><td>https://www.bbc.co.uk/news/world-us-canada-44854370                </td><td>a40f669e2a0ad253                                                   </td></tr>\n",
       "\t<tr><td>BBC News - World                                                   </td><td>ECHR condemns Pussy Riot and Anna Politkovskaya cases              </td><td>2018-07-17 12:08:10                                                </td><td>https://www.bbc.co.uk/news/world-europe-44857461                   </td><td>b8cb4b10cc9746d4                                                   </td></tr>\n",
       "\t<tr><td>BBC News - World                                                   </td><td>Trump to redesign Air Force One to be 'red, white and blue'        </td><td>2018-07-17 18:36:31                                                </td><td>https://www.bbc.co.uk/news/world-us-canada-44865953                </td><td>21587f160eb6ccd5                                                   </td></tr>\n",
       "\t<tr><td>BBC News - World                                                   </td><td>Spain sexual consent: PM Pedro Sanchez promises new law            </td><td>2018-07-17 17:35:31                                                </td><td>https://www.bbc.co.uk/news/world-europe-44866759                   </td><td>e2ee037064703bb6                                                   </td></tr>\n",
       "\t<tr><td>BBC News - World                                                   </td><td>Kim Jong-un blasts delays in North Korean economic projects        </td><td>2018-07-17 13:04:13                                                </td><td>https://www.bbc.co.uk/news/world-asia-44855699                     </td><td>6a3481bfd42e59de                                                   </td></tr>\n",
       "\t<tr><td>BBC News - World                                                   </td><td>Israel suspends fuel deliveries to Gaza over arson attacks         </td><td>2018-07-17 11:06:33                                                </td><td>https://www.bbc.co.uk/news/world-middle-east-44858637              </td><td>f69cd308f2c350c2                                                   </td></tr>\n",
       "\t<tr><td>BBC News - World                                                   </td><td>Las Vegas shooting: Mandalay Bay hotel owner sues 1,000 victims    </td><td>2018-07-17 13:58:10                                                </td><td>https://www.bbc.co.uk/news/world-us-canada-44859238                </td><td>5aae1479a20a9962                                                   </td></tr>\n",
       "\t<tr><td>BBC News - World                                                   </td><td>Houston police arrest 'mattress murders' suspect                   </td><td>2018-07-17 15:53:23                                                </td><td>https://www.bbc.co.uk/news/world-us-canada-44854368                </td><td>2c0aa4ddc22d3c30                                                   </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|lllll}\n",
       " feed & title & date & link & hash\\\\\n",
       "\\hline\n",
       "\t BBC News - World                                                    & Trump-Putin summit: US president reverses remark on Russia meddling & 2018-07-17 20:52:59                                                 & https://www.bbc.co.uk/news/world-us-canada-44864739                 & 0bc39dc7f5641a1d                                                   \\\\\n",
       "\t BBC News - World                                                    & Barack Obama condemns disregard for facts                           & 2018-07-17 18:31:16                                                 & https://www.bbc.co.uk/news/world-africa-44858937                    & ff2a4b417287dd7e                                                   \\\\\n",
       "\t BBC News - World                                                    & Alabama employee gets new car from boss after 20-mile walk          & 2018-07-17 16:20:18                                                 & https://www.bbc.co.uk/news/world-us-canada-44854370                 & a40f669e2a0ad253                                                   \\\\\n",
       "\t BBC News - World                                                    & ECHR condemns Pussy Riot and Anna Politkovskaya cases               & 2018-07-17 12:08:10                                                 & https://www.bbc.co.uk/news/world-europe-44857461                    & b8cb4b10cc9746d4                                                   \\\\\n",
       "\t BBC News - World                                                    & Trump to redesign Air Force One to be 'red, white and blue'         & 2018-07-17 18:36:31                                                 & https://www.bbc.co.uk/news/world-us-canada-44865953                 & 21587f160eb6ccd5                                                   \\\\\n",
       "\t BBC News - World                                                    & Spain sexual consent: PM Pedro Sanchez promises new law             & 2018-07-17 17:35:31                                                 & https://www.bbc.co.uk/news/world-europe-44866759                    & e2ee037064703bb6                                                   \\\\\n",
       "\t BBC News - World                                                    & Kim Jong-un blasts delays in North Korean economic projects         & 2018-07-17 13:04:13                                                 & https://www.bbc.co.uk/news/world-asia-44855699                      & 6a3481bfd42e59de                                                   \\\\\n",
       "\t BBC News - World                                                    & Israel suspends fuel deliveries to Gaza over arson attacks          & 2018-07-17 11:06:33                                                 & https://www.bbc.co.uk/news/world-middle-east-44858637               & f69cd308f2c350c2                                                   \\\\\n",
       "\t BBC News - World                                                    & Las Vegas shooting: Mandalay Bay hotel owner sues 1,000 victims     & 2018-07-17 13:58:10                                                 & https://www.bbc.co.uk/news/world-us-canada-44859238                 & 5aae1479a20a9962                                                   \\\\\n",
       "\t BBC News - World                                                    & Houston police arrest 'mattress murders' suspect                    & 2018-07-17 15:53:23                                                 & https://www.bbc.co.uk/news/world-us-canada-44854368                 & 2c0aa4ddc22d3c30                                                   \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "   feed            \n",
       "1  BBC News - World\n",
       "2  BBC News - World\n",
       "3  BBC News - World\n",
       "4  BBC News - World\n",
       "5  BBC News - World\n",
       "6  BBC News - World\n",
       "7  BBC News - World\n",
       "8  BBC News - World\n",
       "9  BBC News - World\n",
       "10 BBC News - World\n",
       "   title                                                              \n",
       "1  Trump-Putin summit: US president reverses remark on Russia meddling\n",
       "2  Barack Obama condemns disregard for facts                          \n",
       "3  Alabama employee gets new car from boss after 20-mile walk         \n",
       "4  ECHR condemns Pussy Riot and Anna Politkovskaya cases              \n",
       "5  Trump to redesign Air Force One to be 'red, white and blue'        \n",
       "6  Spain sexual consent: PM Pedro Sanchez promises new law            \n",
       "7  Kim Jong-un blasts delays in North Korean economic projects        \n",
       "8  Israel suspends fuel deliveries to Gaza over arson attacks         \n",
       "9  Las Vegas shooting: Mandalay Bay hotel owner sues 1,000 victims    \n",
       "10 Houston police arrest 'mattress murders' suspect                   \n",
       "   date                link                                                 \n",
       "1  2018-07-17 20:52:59 https://www.bbc.co.uk/news/world-us-canada-44864739  \n",
       "2  2018-07-17 18:31:16 https://www.bbc.co.uk/news/world-africa-44858937     \n",
       "3  2018-07-17 16:20:18 https://www.bbc.co.uk/news/world-us-canada-44854370  \n",
       "4  2018-07-17 12:08:10 https://www.bbc.co.uk/news/world-europe-44857461     \n",
       "5  2018-07-17 18:36:31 https://www.bbc.co.uk/news/world-us-canada-44865953  \n",
       "6  2018-07-17 17:35:31 https://www.bbc.co.uk/news/world-europe-44866759     \n",
       "7  2018-07-17 13:04:13 https://www.bbc.co.uk/news/world-asia-44855699       \n",
       "8  2018-07-17 11:06:33 https://www.bbc.co.uk/news/world-middle-east-44858637\n",
       "9  2018-07-17 13:58:10 https://www.bbc.co.uk/news/world-us-canada-44859238  \n",
       "10 2018-07-17 15:53:23 https://www.bbc.co.uk/news/world-us-canada-44854368  \n",
       "   hash            \n",
       "1  0bc39dc7f5641a1d\n",
       "2  ff2a4b417287dd7e\n",
       "3  a40f669e2a0ad253\n",
       "4  b8cb4b10cc9746d4\n",
       "5  21587f160eb6ccd5\n",
       "6  e2ee037064703bb6\n",
       "7  6a3481bfd42e59de\n",
       "8  f69cd308f2c350c2\n",
       "9  5aae1479a20a9962\n",
       "10 2c0aa4ddc22d3c30"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "## GATHER RAW DATA\n",
    "\n",
    "# Define links for feeds\n",
    "feeds <- c(\"http://feeds.bbci.co.uk/news/world/rss.xml\",\n",
    "            \"http://feeds.bbci.co.uk/news/rss.xml\",\n",
    "            \"http://feeds.skynews.com/feeds/rss/uk.xml\",\n",
    "            \"http://feeds.skynews.com/feeds/rss/world.xml\",\n",
    "            \"http://feeds.skynews.com/feeds/rss/us.xml\",\n",
    "            \"http://feeds.reuters.com/Reuters/domesticNews\",\n",
    "            \"http://feeds.reuters.com/Reuters/worldNews\",\n",
    "            \"http://feeds.foxnews.com/foxnews/national\",\n",
    "            \"http://feeds.foxnews.com/foxnews/world\",\n",
    "            \"http://rssfeeds.usatoday.com/UsatodaycomWorld-TopStories\",\n",
    "            \"http://rssfeeds.usatoday.com/UsatodaycomNation-TopStories\",\n",
    "            \"http://rss.nytimes.com/services/xml/rss/nyt/World.xml\",\n",
    "            \"http://www.nytimes.com/services/xml/rss/nyt/Africa.xml\",\n",
    "            \"http://www.nytimes.com/services/xml/rss/nyt/Americas.xml\",\n",
    "            \"http://www.nytimes.com/services/xml/rss/nyt/AsiaPacific.xml\",\n",
    "            \"http://www.nytimes.com/services/xml/rss/nyt/Europe.xml\",\n",
    "            \"http://www.nytimes.com/services/xml/rss/nyt/MiddleEast.xml\",\n",
    "            \"http://www.nytimes.com/services/xml/rss/nyt/US.xml\",\n",
    "            \"http://www.telegraph.co.uk/news/rss.xml\"\n",
    "            )\n",
    "\n",
    "\n",
    "#download the dataset\n",
    "dataset <- \n",
    "    #iterate through each feed address\n",
    "    foreach(i=1:length(feeds), .combine=rbind) %do% {\n",
    "        tryCatch({\n",
    "            # extract items from each feed\n",
    "            extract <- feed.extract(feeds[i])\n",
    "            # return items with additional field of parent feed        \n",
    "            cbind.data.frame(feed = extract$title, extract$items)\n",
    "         }, error = function(e) { NULL }) #return NULL on an error (i.e. ignore it)\n",
    "    }\n",
    "\n",
    "#remove any duplicate entries, by checking each items url\n",
    "dataset <- dataset[match(unique(dataset$link), dataset$link),]\n",
    "\n",
    "#titles <- sapply(dataset$title, function(s) {(strsplit(gsub(\"[[:punct:]]\", \" \", tolower(s)), \" \")) })\n",
    "\n",
    "#show first 10\n",
    "dataset[1:10,]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Excellent! There you have the top 10 stories from the feeds we investigated. \n",
    "\n",
    "Believe it or not, that's a pretty big step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "290"
      ],
      "text/latex": [
       "290"
      ],
      "text/markdown": [
       "290"
      ],
      "text/plain": [
       "[1] 290"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nrow(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#feed contents\n",
    "#library(rvest)\n",
    "\n",
    "contents <- foreach(i = 1:nrow(dataset), .combine = rbind, .packages = \"rvest\") %dopar% {\n",
    "    #i <- 10\n",
    "    tryCatch({\n",
    "        page <- read_html(dataset$link[i])\n",
    "        paragraphs <- html_nodes(page, \"p\")\n",
    "        p_classes <- html_attr(paragraphs, \"class\")\n",
    "        p_text <- html_text(paragraphs)\n",
    "        words <- as.character(unlist(sapply(p_text[is.na(p_classes) | grepl(\"intro\", tolower(p_classes))],\n",
    "                                            function(s) { strsplit(s, \" \")})))\n",
    "        out <- sapply(words[1:100], function(s) { tolower(gsub(\"[^[:alnum:][:space:]]\", \"\", s)) })\n",
    "        names(out) <- NULL\n",
    "        #c(hash = dataset$hash[i], out)\n",
    "        c(id=i, out)\n",
    "    }, error = function(e) { \"\" })\n",
    "}\n",
    "#contents[1,]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "272"
      ],
      "text/latex": [
       "272"
      ],
      "text/markdown": [
       "272"
      ],
      "text/plain": [
       "[1] 272"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nrow(contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## VECTORISE DATA\n",
    "\n",
    "#create wordvector\n",
    "contentWords <- table(c(contents))\n",
    "contentWords <- cbind.data.frame(word = tolower(names(contentWords)[1:length(names(contentWords))]),\n",
    "                                 count = contentWords)\n",
    "\n",
    "wordVector <- unique(c(tolower(unlist(titles)),\n",
    "                       tolower(unlist(contents))))\n",
    "wordVector <- wordVector[wordVector != \"\"]\n",
    "\n",
    "\n",
    "vectorisedData <- foreach(i = 1:nrow(dataset), .combine=rbind) %dopar% {\n",
    "    #i <- 1\n",
    "    tVector <- integer(length(wordVector))\n",
    "    row <- contents[contents[, \"id\"] == i,]\n",
    "    countVector <- table(c(titles[[i]], row[2:length(row)]))\n",
    "    for (j in 1:length(countVector)) {\n",
    "        index <- match(names(countVector)[j], wordVector)\n",
    "        tVector[index] <- countVector[j]\n",
    "    }\n",
    "    t(tVector)\n",
    "    #vectorisedData <- rbind.data.frame(vectorisedData, t(as.data.frame(tVector))) #tVector\n",
    "}\n",
    "names(vectorisedData) <- wordVector\n",
    "\n",
    "vectorisedData <- as.matrix(vectorisedData)\n",
    "colnames(vectorisedData) <- wordVector\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in cor(vectorisedData):\n",
      "\"the standard deviation is zero\""
     ]
    }
   ],
   "source": [
    "\n",
    "## Word Bundles\n",
    "correlationmatrix <- cor(vectorisedData)\n",
    "bundles <- as.data.frame(foreach(i = 1:ncol(vectorisedData), .combine = rbind) %do% {\n",
    "    #i<-1\n",
    "    vec <- correlationmatrix[, i]\n",
    "    bundle <- vec[vec > 0.9]\n",
    "    c(id = i,\n",
    "      bundle = paste(names(bundle[!is.na(bundle)]), collapse = \"-\"),\n",
    "      value = sum(bundle[!is.na(bundle)]),\n",
    "      first = colnames(correlationmatrix)[i],\n",
    "      length = length(bundle[!is.na(bundle)]))\n",
    "})\n",
    "bundles <- bundles[match(unique(bundles$bundle[as.numeric(bundles$value) > 1]), bundles$bundle),]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## Synonyms\n",
    "library(stringdist)\n",
    "similaritymatrix <- matrix(foreach(i = 1:length(wordVector), .combine = rbind, .packages = \"stringdist\") %dopar% { stringdist(wordVector[i], wordVector) },\n",
    "                           ncol = length(wordVector),\n",
    "                           nrow = length(wordVector),\n",
    "                           dimnames = list(wordVector,wordVector))\n",
    "synonyms <- as.data.frame(foreach(i = 1:ncol(vectorisedData), .combine = rbind) %do% {\n",
    "    #i<-1\n",
    "    vec <- similaritymatrix[, i]\n",
    "    synonym <- vec[vec < 0.25 * length(colnames(similaritymatrix)[i])]\n",
    "    c(id = i,\n",
    "      synonym = paste(names(synonym[!is.na(synonym)]), collapse = \"-\"),\n",
    "      value = sum(synonym[!is.na(synonym)]))\n",
    "})\n",
    "synonyms <- synonyms[match(unique(synonyms$synonym[as.numeric(synonyms$value) > 1]), synonyms$synonym),]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "ERROR",
     "evalue": "Error in eval(expr, envir, enclos): could not find function \"top_n\"\n",
     "output_type": "error",
     "traceback": [
      "Error in eval(expr, envir, enclos): could not find function \"top_n\"\nTraceback:\n"
     ]
    }
   ],
   "source": [
    "\n",
    "## SELECT FEATURES\n",
    "analytics <- cbind.data.frame(wordVector,\n",
    "                              count = sapply(1:length(wordVector), function(w) { sum(vectorisedData[, w]) }),\n",
    "                              mean = sapply(1:length(wordVector), function(w) { mean(vectorisedData[, w]) }),\n",
    "                              stdev = sapply(1:length(wordVector), function(w) { sd(vectorisedData[, w]) }),\n",
    "                              max = sapply(1:length(wordVector), function(w) { max(vectorisedData[, w]) }),\n",
    "                              min = sapply(1:length(wordVector), function(w) { min(vectorisedData[, w]) }))\n",
    "\n",
    "analytics$varration <- sapply(1:nrow(analytics), function(a) { analytics$stdev[a] / analytics$mean[a] })\n",
    "\n",
    "test <- top_n(analytics, 50, analytics$count)\n",
    "test <- analytics[rank(analytics$count, ties.method = \"random\"),]\n",
    "\n",
    "lengths <- sapply(1:nrow(vectorisedData), function(i) { sum(vectorisedData[i,]) })\n",
    "lengths <- cbind.data.frame(length = lengths)\n",
    "\n",
    "\n",
    "library(dplyr)\n",
    "#analytics[sort(analytics$count, decreasing = T),]\n",
    "#selectedFeatures <- as.character(analytics[!is.na(analytics$varration) & analytics$varration > 2,]$wordVector)\n",
    "#selectedFeatures <- as.character(top_n(analytics, 200, analytics$varration)$wordVector)\n",
    "#selectedFeatures <- names(vectorisedData)\n",
    "selectedFeatures <- as.character(bundles$first[as.numeric(bundles$length)>2])\n",
    "\n",
    "featureSet <- matrix(as.numeric(vectorisedData[, selectedFeatures]),nrow = nrow(vectorisedData))#,\n",
    "                               #date = with(dataset, (as.numeric(date) - quantile(as.numeric(date), 0.05)) / (mean(as.numeric(date)) - quantile(as.numeric(date), 0.05))),\n",
    "                               #hash_ = dataset$hash)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## K MEANS CLUSTERING\n",
    "cartesianDistance <- function(v1, v2) {\n",
    "    #sum(mapply(function(c1, c2) {(c1 - c2) ^ 2 }, v1, v2))^0.5\n",
    "    ((v1 - v2) %*% t(v1 - v2))[[1]]^0.5\n",
    "}\n",
    "\n",
    "generateCentroid <- function() {\n",
    "    centroid <- double(length(selectedFeatures))\n",
    "    #centroid[sample(1:length(selectedFeatures), round(mean(lengths$length) + 1))] <- 1\n",
    "    centroid <- as.numeric(featureSet[sample(1:nrow(dataset),1),])\n",
    "    centroid\n",
    "}\n",
    "\n",
    "k <- 10\n",
    "centroids <- list()\n",
    "for (i in 1:k) {\n",
    "    centroids <- rbind.data.frame(centroids, generateCentroid())\n",
    "}\n",
    "centroids <- as.matrix(centroids)\n",
    "colnames(centroids)<- NULL  \n",
    "\n",
    "G <- 100\n",
    "history <- list()\n",
    "g <- 1\n",
    "while (g <= G) {\n",
    "    dataset$cluster <- foreach(i = 1:nrow(featureSet), .combine = rbind) %dopar% {\n",
    "        #i <- 1\n",
    "        distances <- sapply(1:k, function(c) {\n",
    "            #c <- 2\n",
    "            V1 <- as.matrix(centroids[c,])\n",
    "            V2 <- as.matrix(featureSet[i, ])\n",
    "            (t(V1-V2) %*% (V1-V2))[[1]]^0.5\n",
    "        })\n",
    "        match(min(distances), distances)\n",
    "    }\n",
    "\n",
    "    newcentroids <- centroids\n",
    "    for (i in 1:k) {\n",
    "        #i <- 2\n",
    "        if (nrow(dataset[dataset$cluster == i, ]) > 1) {\n",
    "            #i <- 1\n",
    "            members <- as.data.frame(featureSet[dataset$cluster == i,])\n",
    "            for (j in 1:length(selectedFeatures)) {\n",
    "                newcentroids[i, j] = mean(members[, j])\n",
    "            }\n",
    "        } else {\n",
    "            newcentroid <- generateCentroid()\n",
    "            for (j in 1:length(selectedFeatures)) {\n",
    "                newcentroids[i, j] = newcentroid[j]\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    lastCentroids <- as.matrix(centroids)\n",
    "    centroids <- as.matrix(newcentroids)\n",
    "\n",
    "    dataset$distance <- foreach(i = 1:nrow(featureSet), .combine = rbind) %dopar% {\n",
    "        # i <- 1\n",
    "        V1 <- as.matrix(centroids[dataset$cluster[i],]) #, nrow = 1)\n",
    "        V2 <- as.matrix(featureSet[i,])\n",
    "        (t(V1 - V2) %*% (V1 - V2))[[1]] ^ 0.5\n",
    "    }\n",
    "                                     \n",
    "    distances <- double(k)\n",
    "    for (i in 1:k) {\n",
    "        distances[i] <- sum(dataset$distance[dataset$cluster == i]) / length(dataset$distance[dataset$cluster == i])\n",
    "    }\n",
    "    history <- rbind.data.frame(history, cbind(g, t(distances), sum(distances)))\n",
    "\n",
    "    g <- g + 1\n",
    "}\n",
    "names(history) <- c(\"generation\", 1:k, \"total\")\n",
    "View(history)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## ANALYSIS\n",
    "\n",
    "test<-dataset[dataset$cluster==1,]\n",
    "View(test)\n",
    "\n",
    "test <- dataset[order(dataset$cluster, dataset$distance),]\n",
    "View(test)\n",
    "\n",
    "test2 <- merge(x = featureSet[, names(featureSet)[!names(featureSet) %in% selectedFeatures]],\n",
    "               y = dataset,\n",
    "               by.x = \"hash_\",\n",
    "               by.y = \"hash\")\n",
    "\n",
    "history\n",
    "\n",
    "cl <- 9\n",
    "result <- top_n(test2[test2$clusters_ == cl,], 10, test2$distance_[test2$clusters_ == cl])\n",
    "View(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.3.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
